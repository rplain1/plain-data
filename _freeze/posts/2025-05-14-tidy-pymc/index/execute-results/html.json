{
  "hash": "fef9a0b3ad8fc940a41bbfd096bb704b",
  "result": {
    "markdown": "---\ntitle: \"TidyPyMC\"\nauthor: \"Ryan Plain\"\ndate: \"2025-05-14\"\ncategories: [Bayesian, PyMC, Plotnine]\nengine: jupyter\ndescription: Grammar of Graphics with PyMC\n---\n\n## Tidybayes in Python would be cool\n\nA few weeks ago, Benjamin Vincent posted [this blog post](https://drbenvincent.github.io/posts/mcmc_grammar_of_graphics.html) on using Bayesian models in Python _and_ leveraging the grammar of graphics for plotting. Please take the time to read that post as this is derived and inteded to augment the ideas shared there.\n\nAt the end of the post, Vincent asked \"It would be interesting to see if this approach is appealing to people.\" My answer to that is... YES‼️\n\nI like `PyMC` and `ArviZ` a lot, but it was a huge blow coming from `R` and libraries like `tidybayes`, `bayesplots`, and others that helped wrangle and visualize the posterior.\n\nI fully agree with the approach of `ArviZ` to work with high-dimensional data, but comming from a stats background it is more intuitive to work with things as dataframes rather than objects whenever it makes sense. This is especially true with visualizations and the grammar of graphics.\n\nI'm not sure how or what the best way to contribute to this, and it was mentioned on bluesky that [GoG-like interface is being developped for ArviZ 1.0](https://bsky.app/profile/sethaxen.com/post/3loaw2tpucs2v). The best thing I can do is create a post for me.\n\n\n## TidyPyMC\n\nThis is definitely subjective, but I think the missing commponent right now is a consistent way to turn the `arviz.InferenceData` object into a dataframe. Both this and the code Vincent shared is highly custom to the model, and from my experience that is typically a common design choice between R and Python libraries. There is tradeoffs to both paradigms.\n\nThere are a couple of plots in `tidybayes` [add_epred_draws()](https://mjskay.github.io/tidybayes/reference/add_predicted_draws.html) and [add_predicted_draws()](https://mjskay.github.io/tidybayes/reference/add_predicted_draws.html) that show some of its capabilities. The goal of this is to replicate them.\n\nTo accomplish this, we will bring the observed data, linear predictions, and posterior predictions in the same dataframe.\n\n### Libraries and data\n\nWe'll use the `mtcars` dataset to replicate some of the `tidybayes` examples.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport pymc as pm\nimport arviz as az\nimport numpy as np\n\nfrom plotnine.data import mtcars\nfrom plotnine import * # elmo_fire.gif namespace, but they mostly start with geom_*\nmtcars.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>mpg</th>\n      <th>cyl</th>\n      <th>disp</th>\n      <th>hp</th>\n      <th>drat</th>\n      <th>wt</th>\n      <th>qsec</th>\n      <th>vs</th>\n      <th>am</th>\n      <th>gear</th>\n      <th>carb</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Mazda RX4</td>\n      <td>21.0</td>\n      <td>6</td>\n      <td>160.0</td>\n      <td>110</td>\n      <td>3.90</td>\n      <td>2.620</td>\n      <td>16.46</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Mazda RX4 Wag</td>\n      <td>21.0</td>\n      <td>6</td>\n      <td>160.0</td>\n      <td>110</td>\n      <td>3.90</td>\n      <td>2.875</td>\n      <td>17.02</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Datsun 710</td>\n      <td>22.8</td>\n      <td>4</td>\n      <td>108.0</td>\n      <td>93</td>\n      <td>3.85</td>\n      <td>2.320</td>\n      <td>18.61</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hornet 4 Drive</td>\n      <td>21.4</td>\n      <td>6</td>\n      <td>258.0</td>\n      <td>110</td>\n      <td>3.08</td>\n      <td>3.215</td>\n      <td>19.44</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hornet Sportabout</td>\n      <td>18.7</td>\n      <td>8</td>\n      <td>360.0</td>\n      <td>175</td>\n      <td>3.15</td>\n      <td>3.440</td>\n      <td>17.02</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Model\n\nThis is an attempt at replicating the model [here](https://mjskay.github.io/tidybayes/reference/add_predicted_draws.html).\n\nThe formula is following `mpg ~ hp * cyl` fit with `brms`.\n\n::: {.callout-note}\nThe scope of this wasn't necessarily to walk through creating a pymc model or walk through the workflow of prior predictive checks, diagnostics, etc. I took the priors from `brms::stancode(brms::brm(mpg ~ hp * cyl, data = mtcars))` in R. I also used `PyMC` over `Bambi`, but both libraries work off the `arviz.InferenceData` object.\n:::\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# build model and sample posterior\nwith pm.Model(\n    coords={\"obs\": mtcars.index, \"predictors\": ['hp', 'cyl']}\n) as mod:\n\n    X = pm.Data(\"X\", mtcars[[\"hp\", \"cyl\"]], dims=(\"obs\", \"predictors\"))\n\n    alpha = pm.StudentT(\"alpha\", nu=3, mu=19.2, sigma=5.4)\n    sigma = pm.HalfStudentT(\"sigma\", nu=3, sigma=5.54)\n    beta = pm.Normal(\"b\", mu=0, sigma=1, dims='predictors')\n\n    mu = pm.Deterministic(\"mu\", alpha + pm.math.dot(X, beta), dims='obs')\n\n    y = pm.Normal(\n        \"y\",\n        mu=mu,\n        sigma=sigma,\n        shape=X.shape[0],\n        observed=mtcars[\"mpg\"],\n        dims=\"obs\",\n    )\n\n    idata = pm.sample(random_seed=527)\n\n# sample posterior predictive\nwith mod as model:\n    pp = pm.sample_posterior_predictive(idata, predictions=True)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [alpha, sigma, b]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\nSampling: [y]\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"140e562c4b2945d4a9bb2ca1cbb926b1\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"e2693ebd0e224602987857e492116c2f\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n```\n:::\n:::\n\n\n### Tidy up\n\nThe biggest takeaway I had from Vincent's post was it wsa possible to get tidy data out of the `arviz.InferenceData` object, and this was by far the most difficult part to get my head around.\n\nFrom `idata.posterior`, we'll take three things:\n\n- global parameters: `sigma`, `alpha`\n- parameters `beta` (2)\n- linear predictions `mu`\n\n\n\nThe key is to understand the dimensions of which attribute you want ot get and which ones are the same.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nprint(f'alpha: {idata.posterior[\"alpha\"].shape}')\nprint(f'sigma: {idata.posterior[\"sigma\"].shape}')\nprint(f'beta: {idata.posterior[\"b\"].shape}')\nprint(f'mu: {idata.posterior[\"mu\"].shape}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nalpha: (4, 1000)\nsigma: (4, 1000)\nbeta: (4, 1000, 2)\nmu: (4, 1000, 32)\n```\n:::\n:::\n\n\n- Both `alpha` and `sigma` are the same shape becuause they are global parameters.\n- `beta` has the same number of draws, each is represented as a row that will pivot\n- `mu` has the same number of draws but for each observation\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nparams = idata.posterior[[\"sigma\", \"alpha\"]].to_dataframe().reset_index()\nbetas = (\n    idata.posterior[\"b\"]\n    .to_dataframe()\n    .reset_index()\n    .pivot(index=[\"chain\", \"draw\"], columns=\"predictors\", values=\"b\")\n    .reset_index()\n)\n\ndf_posterior = params.merge(betas, on=[\"chain\", \"draw\"])\n\ndf_posterior = (\n    idata.posterior[\"mu\"]\n    .to_dataframe()\n    .reset_index()\n    .merge(mtcars[[\"cyl\", \"mpg\", \"hp\"]], left_on=\"obs\", right_on=mtcars.index)\n    .merge(params, on=[\"chain\", \"draw\"])\n    .merge(betas, on=[\"chain\", \"draw\"], suffixes=[\"\", \"_b\"])\n    .assign( # for plotting later\n        group=lambda x: x.cyl.astype(str)\n        + \"_\"\n        + x.draw.astype(str)\n        + \"_\"\n        + x.chain.astype(str)\n    )\n)\n\ndf_posterior\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chain</th>\n      <th>draw</th>\n      <th>obs</th>\n      <th>mu</th>\n      <th>cyl</th>\n      <th>mpg</th>\n      <th>hp</th>\n      <th>sigma</th>\n      <th>alpha</th>\n      <th>cyl_b</th>\n      <th>hp_b</th>\n      <th>group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>22.463651</td>\n      <td>6</td>\n      <td>21.0</td>\n      <td>110</td>\n      <td>4.074876</td>\n      <td>33.091908</td>\n      <td>-0.731355</td>\n      <td>-0.056728</td>\n      <td>6_0_0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>22.463651</td>\n      <td>6</td>\n      <td>21.0</td>\n      <td>110</td>\n      <td>4.074876</td>\n      <td>33.091908</td>\n      <td>-0.731355</td>\n      <td>-0.056728</td>\n      <td>6_0_0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>24.890745</td>\n      <td>4</td>\n      <td>22.8</td>\n      <td>93</td>\n      <td>4.074876</td>\n      <td>33.091908</td>\n      <td>-0.731355</td>\n      <td>-0.056728</td>\n      <td>4_0_0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>22.463651</td>\n      <td>6</td>\n      <td>21.4</td>\n      <td>110</td>\n      <td>4.074876</td>\n      <td>33.091908</td>\n      <td>-0.731355</td>\n      <td>-0.056728</td>\n      <td>6_0_0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>17.313594</td>\n      <td>8</td>\n      <td>18.7</td>\n      <td>175</td>\n      <td>4.074876</td>\n      <td>33.091908</td>\n      <td>-0.731355</td>\n      <td>-0.056728</td>\n      <td>8_0_0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>127995</th>\n      <td>3</td>\n      <td>999</td>\n      <td>27</td>\n      <td>24.983972</td>\n      <td>4</td>\n      <td>30.4</td>\n      <td>113</td>\n      <td>2.481254</td>\n      <td>35.978550</td>\n      <td>-2.033584</td>\n      <td>-0.025312</td>\n      <td>4_999_3</td>\n    </tr>\n    <tr>\n      <th>127996</th>\n      <td>3</td>\n      <td>999</td>\n      <td>28</td>\n      <td>13.027543</td>\n      <td>8</td>\n      <td>15.8</td>\n      <td>264</td>\n      <td>2.481254</td>\n      <td>35.978550</td>\n      <td>-2.033584</td>\n      <td>-0.025312</td>\n      <td>8_999_3</td>\n    </tr>\n    <tr>\n      <th>127997</th>\n      <td>3</td>\n      <td>999</td>\n      <td>29</td>\n      <td>19.347468</td>\n      <td>6</td>\n      <td>19.7</td>\n      <td>175</td>\n      <td>2.481254</td>\n      <td>35.978550</td>\n      <td>-2.033584</td>\n      <td>-0.025312</td>\n      <td>6_999_3</td>\n    </tr>\n    <tr>\n      <th>127998</th>\n      <td>3</td>\n      <td>999</td>\n      <td>30</td>\n      <td>11.230399</td>\n      <td>8</td>\n      <td>15.0</td>\n      <td>335</td>\n      <td>2.481254</td>\n      <td>35.978550</td>\n      <td>-2.033584</td>\n      <td>-0.025312</td>\n      <td>8_999_3</td>\n    </tr>\n    <tr>\n      <th>127999</th>\n      <td>3</td>\n      <td>999</td>\n      <td>31</td>\n      <td>25.085220</td>\n      <td>4</td>\n      <td>21.4</td>\n      <td>109</td>\n      <td>2.481254</td>\n      <td>35.978550</td>\n      <td>-2.033584</td>\n      <td>-0.025312</td>\n      <td>4_999_3</td>\n    </tr>\n  </tbody>\n</table>\n<p>128000 rows × 12 columns</p>\n</div>\n```\n:::\n:::\n\n\nThe critical takeaway I had from implementing this was learn to leverage `coords` and `dims` in the model container. This makes it easier to work with the data later, especially as dimensions increase (i.e. groups in a multilevel model).\n\nThis sets the posterior to be represented in a tidy dataframe, exactly how Vincent did it. I'm really interested what ways we can cofigure the atributes with `PyMC` to make this generalize across different models and data.\n\n::: {.callout-note}\nI've come back to this and realized adding in the parameters doesn't make it \"tidy\", and also doesn't get used in the plots. It is still beneficial to include how to go about joining the parameters posterior draws to the data, and anyway... this post is for future me.\n:::\n\n### Posterior predictive\n\nOne way would be to do this would be to use `arviz.summary()` on the sampled posterior predictions. This is a common workflow I would do with `brms` and `tidybayes` of parsing parameter outputs name to match the group, or join an id with the original dataset.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndf_predictions = az.summary(pp)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/ryan/git-repos/plain-data/.venv/lib/python3.12/site-packages/arviz/stats/stats.py:1359: UserWarning: Selecting first found group: predictions\n```\n:::\n:::\n\n\nNext steps to join it with the observed data.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ndf_predictions.index = df_predictions.index.str.extract(r\"y\\[(.*?)\\]\")[0]\n\ndf_predictions = df_predictions.merge(mtcars[[\"hp\", \"cyl\", \"mpg\"]], on=df_predictions.index)\ndf_predictions.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>key_0</th>\n      <th>mean</th>\n      <th>sd</th>\n      <th>hdi_3%</th>\n      <th>hdi_97%</th>\n      <th>mcse_mean</th>\n      <th>mcse_sd</th>\n      <th>ess_bulk</th>\n      <th>ess_tail</th>\n      <th>r_hat</th>\n      <th>hp</th>\n      <th>cyl</th>\n      <th>mpg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>21.554</td>\n      <td>3.518</td>\n      <td>14.560</td>\n      <td>27.887</td>\n      <td>0.061</td>\n      <td>0.044</td>\n      <td>3292.0</td>\n      <td>3666.0</td>\n      <td>1.0</td>\n      <td>110</td>\n      <td>6</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>21.470</td>\n      <td>3.503</td>\n      <td>14.949</td>\n      <td>27.871</td>\n      <td>0.056</td>\n      <td>0.044</td>\n      <td>3869.0</td>\n      <td>3845.0</td>\n      <td>1.0</td>\n      <td>110</td>\n      <td>6</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>25.176</td>\n      <td>3.573</td>\n      <td>17.968</td>\n      <td>31.616</td>\n      <td>0.059</td>\n      <td>0.044</td>\n      <td>3723.0</td>\n      <td>3477.0</td>\n      <td>1.0</td>\n      <td>93</td>\n      <td>4</td>\n      <td>22.8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>21.540</td>\n      <td>3.545</td>\n      <td>14.597</td>\n      <td>27.981</td>\n      <td>0.056</td>\n      <td>0.042</td>\n      <td>3940.0</td>\n      <td>3775.0</td>\n      <td>1.0</td>\n      <td>110</td>\n      <td>6</td>\n      <td>21.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>16.393</td>\n      <td>3.563</td>\n      <td>10.187</td>\n      <td>23.717</td>\n      <td>0.057</td>\n      <td>0.046</td>\n      <td>3934.0</td>\n      <td>3670.0</td>\n      <td>1.0</td>\n      <td>175</td>\n      <td>8</td>\n      <td>18.7</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThis worked well with the named index on `mtcars`. I'm not a fan of `pandas`, and I've long forgotten a lot of tips and tricks to work with the nuances of `pandas` after a couple of years of using `polars`. For future me, I'm going to include a standarad approach of working with the posterior.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ndf_posterior_predictive = (\n    pp.predictions[\"y\"]\n    .to_dataframe()\n    .reset_index()\n    .merge(mtcars[[\"cyl\", \"hp\"]], left_on=\"obs\", right_on=mtcars.index)\n)\n\ndf_posterior_predictive\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chain</th>\n      <th>draw</th>\n      <th>obs</th>\n      <th>y</th>\n      <th>cyl</th>\n      <th>hp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>19.104229</td>\n      <td>6</td>\n      <td>110</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>25.039315</td>\n      <td>6</td>\n      <td>110</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>24.256567</td>\n      <td>4</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>19.098882</td>\n      <td>6</td>\n      <td>110</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>15.877768</td>\n      <td>8</td>\n      <td>175</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>127995</th>\n      <td>3</td>\n      <td>999</td>\n      <td>27</td>\n      <td>26.447811</td>\n      <td>4</td>\n      <td>113</td>\n    </tr>\n    <tr>\n      <th>127996</th>\n      <td>3</td>\n      <td>999</td>\n      <td>28</td>\n      <td>8.939379</td>\n      <td>8</td>\n      <td>264</td>\n    </tr>\n    <tr>\n      <th>127997</th>\n      <td>3</td>\n      <td>999</td>\n      <td>29</td>\n      <td>19.937614</td>\n      <td>6</td>\n      <td>175</td>\n    </tr>\n    <tr>\n      <th>127998</th>\n      <td>3</td>\n      <td>999</td>\n      <td>30</td>\n      <td>15.226820</td>\n      <td>8</td>\n      <td>335</td>\n    </tr>\n    <tr>\n      <th>127999</th>\n      <td>3</td>\n      <td>999</td>\n      <td>31</td>\n      <td>29.357202</td>\n      <td>4</td>\n      <td>109</td>\n    </tr>\n  </tbody>\n</table>\n<p>128000 rows × 6 columns</p>\n</div>\n```\n:::\n:::\n\n\nThe data is aggregated to match the `az.summary()` output since this particular `geom_ribbon()` visualization will only need the HDI values of the posterior predictive distribution.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ndf_predictions = (\n    df_posterior_predictive.groupby([\"obs\", \"cyl\", \"hp\"])\n    .agg(\n        pp_mean=(\"y\", \"mean\"),\n        pp_min=(\"y\", lambda x: x.quantile(0.03)),\n        pp_max=(\"y\", lambda x: x.quantile(0.97)),\n    )\n    .reset_index()\n)\ndf_predictions.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>obs</th>\n      <th>cyl</th>\n      <th>hp</th>\n      <th>pp_mean</th>\n      <th>pp_min</th>\n      <th>pp_max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>6</td>\n      <td>110</td>\n      <td>21.554171</td>\n      <td>14.872339</td>\n      <td>28.276621</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>6</td>\n      <td>110</td>\n      <td>21.469598</td>\n      <td>14.971328</td>\n      <td>27.914067</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>4</td>\n      <td>93</td>\n      <td>25.175523</td>\n      <td>18.266339</td>\n      <td>31.997126</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>6</td>\n      <td>110</td>\n      <td>21.539521</td>\n      <td>14.693196</td>\n      <td>28.122148</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>8</td>\n      <td>175</td>\n      <td>16.392580</td>\n      <td>9.748206</td>\n      <td>23.448341</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### The plot is coming together\n\nPlotnine! With the grammar of graphics, we're able to:\n\n- use different datasets\n- layer aesthetics together\n- think about plots in terms of data\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n# sample draws for plotting purposes\nsamples = np.random.choice(\n    [x for x in range(999)], size=int(5), replace=False\n)\n\n(\n    ggplot(mtcars, aes(\"hp\", \"mpg\", color=\"factor(cyl)\", fill=\"factor(cyl)\"))\n    + geom_ribbon(\n        aes(y=\"pp_mean\", ymin=\"pp_min\", ymax=\"pp_max\"), data=df_predictions, alpha=0.2\n    )\n    + geom_line(\n        aes(y=\"mu\", group=\"group\"),\n        data=df_posterior[df_posterior.draw.isin(samples)],\n        alpha=0.6,\n    )\n    + geom_point()\n    + theme_minimal()\n    + labs(color='cyl', fill='cyl')\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-10-output-1.png){width=672 height=480}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n<script src=\"https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js\" crossorigin=\"anonymous\"></script>\n"
      ],
      "include-after-body": [
        "<script type=application/vnd.jupyter.widget-state+json>\n{\"state\":{\"140e562c4b2945d4a9bb2ca1cbb926b1\":{\"model_module\":\"@jupyter-widgets/output\",\"model_module_version\":\"1.0.0\",\"model_name\":\"OutputModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/output\",\"_model_module_version\":\"1.0.0\",\"_model_name\":\"OutputModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/output\",\"_view_module_version\":\"1.0.0\",\"_view_name\":\"OutputView\",\"layout\":\"IPY_MODEL_3c193414ed6845de8b21c333f3b59ba1\",\"msg_id\":\"\",\"outputs\":[{\"data\":{\"text/html\":\"<pre style=\\\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\\\">                                                                                                                   \\n <span style=\\\"font-weight: bold\\\"> Progress                 </span> <span style=\\\"font-weight: bold\\\"> Draws </span> <span style=\\\"font-weight: bold\\\"> Divergences </span> <span style=\\\"font-weight: bold\\\"> Step size </span> <span style=\\\"font-weight: bold\\\"> Grad evals </span> <span style=\\\"font-weight: bold\\\"> Sampling Speed  </span> <span style=\\\"font-weight: bold\\\"> Elapsed </span> <span style=\\\"font-weight: bold\\\"> Remaining </span> \\n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \\n  <span style=\\\"color: #1f77b4; text-decoration-color: #1f77b4\\\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.11        15           1404.80 draws/s   0:00:01   0:00:00    \\n  <span style=\\\"color: #1f77b4; text-decoration-color: #1f77b4\\\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.15        31           1425.02 draws/s   0:00:01   0:00:00    \\n  <span style=\\\"color: #1f77b4; text-decoration-color: #1f77b4\\\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.18        15           1376.31 draws/s   0:00:01   0:00:00    \\n  <span style=\\\"color: #1f77b4; text-decoration-color: #1f77b4\\\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   2000    0             0.19        31           1398.46 draws/s   0:00:01   0:00:00    \\n                                                                                                                   \\n</pre>\\n\",\"text/plain\":\"                                                                                                                   \\n \\u001b[1m \\u001b[0m\\u001b[1mProgress                \\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mDraws\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mDivergences\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mStep size\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mGrad evals\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mSampling Speed \\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mElapsed\\u001b[0m\\u001b[1m \\u001b[0m \\u001b[1m \\u001b[0m\\u001b[1mRemaining\\u001b[0m\\u001b[1m \\u001b[0m \\n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \\n  \\u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m   2000    0             0.11        15           1404.80 draws/s   0:00:01   0:00:00    \\n  \\u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m   2000    0             0.15        31           1425.02 draws/s   0:00:01   0:00:00    \\n  \\u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m   2000    0             0.18        15           1376.31 draws/s   0:00:01   0:00:00    \\n  \\u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m   2000    0             0.19        31           1398.46 draws/s   0:00:01   0:00:00    \\n                                                                                                                   \\n\"},\"metadata\":{},\"output_type\":\"display_data\"}],\"tabbable\":null,\"tooltip\":null}},\"3c193414ed6845de8b21c333f3b59ba1\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"cc377b9dfc174bb791fe0bea96d31e77\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"e2693ebd0e224602987857e492116c2f\":{\"model_module\":\"@jupyter-widgets/output\",\"model_module_version\":\"1.0.0\",\"model_name\":\"OutputModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/output\",\"_model_module_version\":\"1.0.0\",\"_model_name\":\"OutputModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/output\",\"_view_module_version\":\"1.0.0\",\"_view_name\":\"OutputView\",\"layout\":\"IPY_MODEL_cc377b9dfc174bb791fe0bea96d31e77\",\"msg_id\":\"\",\"outputs\":[{\"data\":{\"text/html\":\"<pre style=\\\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\\\">Sampling ... <span style=\\\"color: #008000; text-decoration-color: #008000\\\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\\\"color: #800080; text-decoration-color: #800080\\\">100%</span> 0:00:00 / 0:00:00\\n</pre>\\n\",\"text/plain\":\"Sampling ... \\u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[35m100%\\u001b[0m 0:00:00 / 0:00:00\\n\"},\"metadata\":{},\"output_type\":\"display_data\"}],\"tabbable\":null,\"tooltip\":null}}},\"version_major\":2,\"version_minor\":0}\n</script>\n"
      ]
    }
  }
}