{
  "hash": "9fe83920009b652a667ff02957a2f557",
  "result": {
    "markdown": "---\ntitle: \"Rython\"\nauthor: \"Ryan Plain\"\ndate: \"2025-05-31\"\ncategories: [Bayesian, PyMC, Reticulate]\ndf-print: kable\ndescription: Bayesian Modeling with PyMC in R with Reticulate.\n---\n\n\n## Bayesian models (Python) + grammar of graphics (R) = ❤️\n\nThis is a nod to the title of [Benjamin T. Vincent's blog post](https://drbenvincent.github.io/posts/mcmc_grammar_of_graphics.html), who inspired me to dive further into PyMC. The reason I started looking into using the grammar of graphics with PyMC, was to reduce a barrier and emulate **tidyverse** as much as possible. What if I instead just... use R and PyMC?\n\nThis is also somewhat of a continuation of my [last post](../2025-05-14-tidy-pymc/), where I used the grammar of graphics to vizualize the posterior distributions from a PyMC model. This required extracting the data from the `arviz.InferenceData` object, and organizing it into a tidy dataframe to work with.\n\n### But why?\n\nIn my last post, I incorrectly implemented the formula for the interaction model `mpg ~ hp * cyl`. I needed to explictly add in a variable so that we have `mpg ~ hp + cyl + hp:cyl`. To correct that, I've added the interaction variable that `lm()` or `brms:` would implicitly handle. Additionally, I centered the variables that would help prevent unnecessary divergece issues that would occur without it.\n\nThis is what I enjoy about PyMC. In my opinion, it is a good blend of needing to be explicit with the data generating process, while still abstracting things like typing, loops, etc., and I find it great for learning. The only problem is is the lack of Tidyverse for everything before and after the model.\n\n\n::: {.callout-note collapse=\"true\"}\nAn R user is probably bewildered and still wondering *but why?* R has access to Stan and several packages that interface with it, including the brilliant `brms` package. Most R users are Stan users.\n\nI started out, like many others, with Statistical Rethinking by Richard McElreath[^sr]. However I abandoned the `rethinking` package too soon, and felt like I didn't know enough to jump into Stan directly. At the same time I had no idea if `brms` was doing exactly what I expected when I started to work on my own messy real world examples, and that is where PyMC came in for me.\n:::\n\n### How\n\nThis was all doable before with Reticulate, but I recently had a chance to use the [new version of Reticulate](https://posit.co/blog/reticulate-1-41/) which uses `uv` to manage the Python environment. I assumed you would need to some degree manage a seperate Python environment for anything signifcant. However, from the post:\n\n> with `py_require()`, Reticulate will automatically create and manage Python environments behind the scenes so you don’t have to.\n\nI had a use case to use it for a simple package integration, and it was wonderful. I came away thinking of ways to push it further.\n\n## Workflow\n\n### Set up with R\n\nLoad up `reticulate` and the `tidyverse`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSys.setenv(RETICULATE_PYTHON = \"managed\")\nlibrary(reticulate)\nlibrary(tidyverse)\nmtcars |>\n  head()\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|                  |  mpg| cyl| disp|  hp| drat|    wt|  qsec| vs| am| gear| carb|\n|:-----------------|----:|---:|----:|---:|----:|-----:|-----:|--:|--:|----:|----:|\n|Mazda RX4         | 21.0|   6|  160| 110| 3.90| 2.620| 16.46|  0|  1|    4|    4|\n|Mazda RX4 Wag     | 21.0|   6|  160| 110| 3.90| 2.875| 17.02|  0|  1|    4|    4|\n|Datsun 710        | 22.8|   4|  108|  93| 3.85| 2.320| 18.61|  1|  1|    4|    1|\n|Hornet 4 Drive    | 21.4|   6|  258| 110| 3.08| 3.215| 19.44|  1|  0|    3|    1|\n|Hornet Sportabout | 18.7|   8|  360| 175| 3.15| 3.440| 17.02|  0|  0|    3|    2|\n|Valiant           | 18.1|   6|  225| 105| 2.76| 3.460| 20.22|  1|  0|    3|    1|\n\n</div>\n:::\n:::\n\n\n::: {.callout-note collapse=\"true\"}\nI set the environment variable for `RETICULATE_PYTHON` to force Reticulate to use an ephemeral environment. I didn't have to do this in an interactive session, but this blog already had a uv proejct setup - and I didn't want it to be used. This could also be configured outside the script or workflow.\n:::\n\n### Reticulate and uv environment\n\nThe function `reticulate::py_require()` will specify which packages are needed for the project or workflow, and pass them to `uv` to resolve all the dependencies and create the Python virtual environment. This is feasible due to how performant `uv` is.\n\nI've listend to enough talks from Charlie Marsh[^charlie] to know I can't fully explain what `uv` does, but an oversimplification of it is that `uv` centralizes package downloads and resolves dependencies at the environment level so that you do not have to reinstall packages across environments.[^uv-overview]\n\n\n::: {.cell}\n\n```{.r .cell-code}\npy_require('pymc')\npy_config()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\npython:         /Users/ryan/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/gKtLQ4Ys-srj2T0OKKL-t/bin/python3\nlibpython:      /Users/ryan/Library/Caches/org.R-project.R/R/reticulate/uv/python/cpython-3.11.12-macos-aarch64-none/lib/libpython3.11.dylib\npythonhome:     /Users/ryan/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/gKtLQ4Ys-srj2T0OKKL-t:/Users/ryan/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/gKtLQ4Ys-srj2T0OKKL-t\nvirtualenv:     /Users/ryan/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/gKtLQ4Ys-srj2T0OKKL-t/bin/activate_this.py\nversion:        3.11.12 (main, May 30 2025, 05:53:55) [Clang 20.1.4 ]\nnumpy:          /Users/ryan/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/gKtLQ4Ys-srj2T0OKKL-t/lib/python3.11/site-packages/numpy\nnumpy_version:  2.2.6\n\nNOTE: Python version was forced by py_require()\n```\n:::\n:::\n\n\nWow! You can see that we have an ephemeral Python environment created with `uv` to use with `reticulate`. Everytime this document is rendered, `reticulate` and `uv` will cache a new virtual environment to use. PyMC and its dependencies only had to be downloaded the first time. Also shown via CLI is that this took only `456ms` on this machine.\n\n### one requirement, many dependencies\n\nSpecifying `pymc` with `py_require()` actually built a Python environment with a list of packages needed, all mapped and configured with `uv`. I've shown some of the most well-known dependencies included.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npy_list_packages() |> dim()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 37  3\n```\n:::\n\n```{.r .cell-code}\npy_list_packages() |> dplyr::filter(package %in% c('pandas', 'scipy', 'matplotlib', 'arviz'))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|package    |version |requirement        |\n|:----------|:-------|:------------------|\n|arviz      |0.21.0  |arviz==0.21.0      |\n|matplotlib |3.10.3  |matplotlib==3.10.3 |\n|pandas     |2.2.3   |pandas==2.2.3      |\n|scipy      |1.15.3  |scipy==1.15.3      |\n\n</div>\n:::\n:::\n\n\n### Set up the data\n\nAs I mentioned before some transformations are needed, and it is great to be able to use the Tidyverse.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmtcars_scaled <- mtcars %>%\n  mutate(\n    hp_c = scale(hp)[, 1], # scale() keeps attributes that need to be removed\n    cyl_c = scale(cyl)[, 1],\n    hp_cyl = hp_c * cyl_c\n  )\n```\n:::\n\n\n### R to Python\n\nPyMC doesn't work with R, and will need objects and data types that it knows how to use. `reticulate::r_to_py()` will handle that.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npandas_mtcars <- r_to_py(mtcars_scaled)\nprint(class(mtcars_scaled))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"data.frame\"\n```\n:::\n\n```{.r .cell-code}\nprint(class(pandas_mtcars))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"pandas.core.frame.DataFrame\"        \"pandas.core.generic.NDFrame\"       \n[3] \"pandas.core.base.PandasObject\"      \"pandas.core.accessor.DirNamesMixin\"\n[5] \"pandas.core.indexing.IndexingMixin\" \"pandas.core.arraylike.OpsMixin\"    \n[7] \"python.builtin.object\"             \n```\n:::\n:::\n\n\nThere are now two datasets:\n\n- **`mtcars_scaled`** is an R `data.frame()` object\n- **`pandas_mtcars`** is a Python `pandas.DataFrame()` object\n\nWe can now begin the Python portion of the workflow.\n\n::: {.callout-warning}\nIntegrating Python and R has come a long way, and is incredibly accessible. There are some edge cases and things to be aware of when converting data and objects between the two. [This post by Karin Hrovatin](https://hrovatin.github.io/posts/r_python/) is one of the best consolidated sources of information to learn from.\n:::\n\n\n### PyMC Model\n\nThe Python sytax would look very similar to this, only now instead of using objects with dot notation, we access methods and attributes with the `$` character. If you are purely a Python developer, this might look obscene. This post requires a specifc subset of being interested in using PyMC and R together and might only be relevant for n=1, but the 1 is me.\n\nPython code from before.\n\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"true\"}\n#|\nwith pm.Model(\n    coords={\"obs\": mtcars.index, \"predictors\": ['hp', 'cyl']}\n) as mod:\n\n    X = pm.Data(\"X\", mtcars[[\"hp\", \"cyl\"]], dims=(\"obs\", \"predictors\"))\n\n    alpha = pm.StudentT(\"alpha\", nu=3, mu=19.2, sigma=5.4)\n    sigma = pm.HalfStudentT(\"sigma\", nu=3, sigma=5.54)\n    beta = pm.Normal(\"b\", mu=0, sigma=1, dims='predictors')\n\n    mu = pm.Deterministic(\"mu\", alpha + pm.math.dot(X, beta), dims='obs')\n\n    y = pm.Normal(\n        \"y\",\n        mu=mu,\n        sigma=sigma,\n        shape=X.shape[0],\n        observed=mtcars[\"mpg\"],\n        dims=\"obs\",\n    )\n\n    idata = pm.sample(random_seed=527)\n\n# sample posterior predictive\nwith mod as model:\n    pp = pm.sample_posterior_predictive(idata, predictions=True)\n```\n:::\n\n\n\nPyMC, but using Reticulate.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# import pymc as pm\npm <- import('pymc', convert = FALSE)\n\nmod <- pm$Model(\n  coords = list(\n    car = pandas_mtcars$index,\n    predictors = c('hp', 'cyl', 'hp_cyl')\n  )\n)\n\n# with pm.Model() as model:\n# ...\nwith(mod, {\n  X <- pm$Data('X', pandas_mtcars$loc[, c('hp', 'cyl', 'hp_cyl')])\n\n  alpha <- pm$StudentT(\"alpha\", nu = 3, mu = 19.2, sigma = 5.4)\n  sigma <- pm$HalfStudentT(\"sigma\", nu = 3, sigma = 5.54)\n  beta <- pm$Normal(\"b\", mu = 0, sigma = 1, dims = 'predictors')\n  mu <- pm$Deterministic(\"mu\", alpha + pm$math$dot(X, beta), dims = 'car')\n\n  y <- pm$Normal(\n    \"y\",\n    mu = mu,\n    sigma = sigma,\n    shape = X$shape[0], # python index\n    observed = pandas_mtcars$mpg,\n    dims = \"car\",\n  )\n  # using a single core and chain because of Quarto page rendering,\n  # normally this would be 4 chains\n  idata = pm$sample(random_seed = 527L, cores = 1L, chains=1L)\n})\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                                \n                              Step      Grad      Sampli…                       \n  Progre…   Draws   Diverg…   size      evals     Speed     Elapsed   Remaini…  \n ────────────────────────────────────────────────────────────────────────────── \n  ━━━━━━━   2000    0         0.19      15        1488.62   0:00:01   0:00:00   \n                                                  draws/s                       \n                                                                                \n```\n:::\n\n```{.r .cell-code}\nwith(mod, {\n  pp = pm$sample_posterior_predictive(idata, predictions = TRUE)\n})\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSampling ... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:00\n```\n:::\n:::\n\n\n### Gotchas\n\nSome quirks to be aware of:\n\n- **`pandas_mtcars$loc[, c('hp', 'cyl', 'hp_cyl')]`**\n  Uses the `.loc` method from pandas, but with R-style dataframe indexing syntax.\n\n- **`X$shape[0]`**\n  Python is 0-based indexed while R is 1-based. Since `X` is a Python object, we use `0` for indexing.\n\n- **`random_seed = 527L`**\n  Integer literals in R require `L` to indicate an integer type, which Python expects here.\n\n\n### Diagnostics\n\nThis plot isn't necessarily useful because I used a single chain for Quarto rendering purposes, but all the `arviz` plots are available. My heart sank a bit when I finally thought about including it. I had already written most of the post and just trying to enhace it a bit. If diagnostic plots weren't available, this would largely be useless or require the problem I was aiming to avoid of duplicating efforts. So this is great to see!\n\n\n::: {.cell}\n\n```{.r .cell-code}\naz <- import('arviz', convert = FALSE)\nplt <- import(\"matplotlib.pyplot\", convert = FALSE)\naz$plot_trace(idata, var_names = c('alpha', 'b', 'sigma'))\nplt$show()\n```\n:::\n\n\n![](trace-plot.png)\n\n\n\n### Posterior\n\nTranslating the PyMC model's `arviz.InferenceData` object and posterior predictions to dataframes is still the same, with the addition of `reticulate::py_to_r()` to convert a pandas dataframe to R.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# posterior mu\ndf_posterior <- idata$posterior$mu$to_dataframe()$reset_index() |>\n  py_to_r() |>\n  as_tibble() |>\n  left_join(rownames_to_column(mtcars, 'car')) |> # R mtcars has rownames for the car\n  mutate(group = paste0(chain, draw, cyl)) # for a particular plot later\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(car)`\n```\n:::\n\n```{.r .cell-code}\n# posterior predictions of mpg\ndf_predictions <- pp$predictions$to_dataframe()$reset_index() |>\n  py_to_r() |>\n  as_tibble() |>\n  left_join(rownames_to_column(mtcars, \"car\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(car)`\n```\n:::\n:::\n\n\nWe're back in R, doing joins with the Tidyverse!\n\n### Plot\n\nNow for my favorite part of this, plot with **ggplot2** and use [tidybayes](https://mjskay.github.io/tidybayes/reference/add_predicted_draws.html) directly!\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_predictions |>\n  ggplot(aes(hp, y, color = as.factor(cyl))) +\n  tidybayes::stat_lineribbon(.width = c(.99, .95, .8, .5), alpha = 0.25) +\n  geom_line(\n    aes(y = mu, group = group),\n    data = df_posterior |> filter(draw %in% round(seq(5, 900, length.out = 5))),\n    alpha = 0.38\n  ) +\n  geom_point(aes(y = mpg), data = mtcars, shape = 21, size = 2, stroke = 1) +\n  scale_fill_brewer(palette = \"Greys\") +\n  theme_light(base_size = 12) +\n  guides(fill = 'none') +\n  labs(\n    x = 'hp',\n    y = 'mpg',\n    color = 'cyl'\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\n## Rython\n\nThis is an opinionated way of using PyMC and the grammar of graphics together to say the least. I really do like PyMC, but I prefer to settle on the data and other parts of the model iteration process with R if possible. There is potential for `reticulate::py_run_string()` as well, if you wanted to be able to drop it directly back into a pure Python environment. Access to an LLM would also be able to easily reformat the R-PyMC model to Python, or at least get it most of the way there.\n\nI'm genuinely impressed by how far integrating R and Python has come. When I started my career, you had to do a bunch of clunky I/O to get features of both languages. Now, in a single workflow, I can use a full-featured Python probabilistic programming library alongside R’s non-standard evaluation for data transformation and visualization.\n\nA typo I had in drafting this at one point was *Rython*, and given my name... I quite like it.\n\n\n[^charlie]: Charlie Marsh is the lead developer of Ruff and discussed `uv` in multiple talks.\n\n[^uv-overview]: `uv` is a Rust-based Python package manager that installs dependencies in a global cache and reuses them in isolated environments, improving reproducibility and speed. For more, see the [uv docs](https://docs.astral.sh/uv/).\n\n[^standard-scaler]: StandardScaler from sci-kit learn does this in the Python, so scaling isn't necessarily the point.\n\n[^sr]: Stistical Rethinking https://xcelab.net/rm/\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}